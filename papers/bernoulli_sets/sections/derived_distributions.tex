\documentclass[ ../main.tex]{subfiles}
\providecommand{\mainx}{..}
\begin{document}
\section{Distributions of binary classification measures}
\label{sec:characteristics}
The error rate on some identically distributed subset is an \emph{expectation}.
However, some \emph{error measures} span multiple subsets, such as positives and negatives.
Any such error measure may be modeled as a \emph{Bernoulli mixture}.

We are typically interested in the error rates of \emph{special} subsets.
For example, if we have a universal set $\Set{X}$ and with probability $\Fun{P}(x)$ an element $x \in \Set{X}$ is tested for membership in a collection of sets over $\Set{X}$, then to reduce the expected error rate on membership tests elements with higher probability of begin tested should be assigned smaller error rates.


The first-order random approximate sets are \emph{parameterized} by the \emph{expected} rates of two types of error, false negative and false positive rates.
In this section, we derive the distribution for these rates.

\begin{definition}
The uncertain number of \emph{negatives} is a random variable denoted by $\RV{N}$ and is statistically dependent on $\RV{R}$,
\begin{equation}
\RV{N} \coloneqq \Card{\SetComplement[\RV{R}]}\,.
\end{equation}
\end{definition}

\begin{definition}
The uncertain number of false positives is a random variable denoted by $\FP$ and is statistically dependent on $\RV{N}$ and $\FPR$,
\begin{equation}
	\FP \coloneqq \RV{N} \FPR\,.
\end{equation}
\end{definition}

The number of false positives given a specific number of negatives is given by the following theorem.
\begin{theorem}
\label{thm:fpbinom}
The random number of false positives $\FP$ given $\RV{N} = n$ in the first-order random approximate set $\AT{\RV{R}}[\fprate]$ is given by
\begin{equation}
	\FP_n \coloneqq n \FPR
\end{equation}
with a distribution given by
\begin{equation}
    \FP_n \sim \bindist(n, \fprate)\,.
\end{equation}
\end{theorem}
\begin{proof}
TODO: Look up the def. given earlier instead for $\FPR$.

By \cref{asm:fprate}, the uncertain outcome that a negative element \emph{tests} as positive is a Bernoulli trial with a mean $\fprate$.
Since there are $n$ such independent and identically distributed trials, the number of false positives is binomially distributed with a mean $n \fprate$.
\end{proof}

The false positive rate $\fprate$ is an \emph{expectation}.
However, the false positive rate of a realization of a random approximate set $\ASet{S}[\fprate]$ is \emph{uncertain}.
\begin{theorem}
\label{thm:fpr}
The random false positive rate $\FPR$ conditioned on $\RV{R} = n$ is denoted by $\FPR_n$ and has a distribution given by
\begin{equation}
    \FPR_n = \frac{\FP_n}{n}\,,
\end{equation}
with an expectation $\fprate$, variance $\fprate(1-\fprate) / n$, and probability mass function
\begin{equation}
	\Pdf_{\FPR_n}\!\FuncArgs*{\fprateob \Given \fprate} = \Pdf_{\FP_n}\!\FuncArgs*{\fprateob n \Given \fprate}\,.
\end{equation}
over the support $\SetBuilder{ \frac{j}{n} \in \BlackboardSet{Q}}{j \in \{0,\ldots,n\}}$.
\end{theorem}
\begin{proof}
By \cref{def:fprate}, the false positive rate is given by the ratio of the number of false positives to the total number of negatives.
By \cref{thm:fpbinom}, given that there are $n$ negatives, the number of false positives is a random variable denoted by $\FP_n$.
Therefore, the false positive rate, as a function of $\FP_n$, is the random variable $\frac{\FP_n}{n}$.
The \emph{expected} false positive rate is
\begin{equation}
    \Expect{\frac{\FP_n}{n}} = \frac{1}{n}\Expect{\FP_n} = \fprate
\end{equation}
and its variance is
\begin{equation}
    \Var{\frac{\FP_n}{n}} = \frac{1}{n^2}\Var{\FP_n} = \frac{\fprate(1-\fprate)}{n}\,.
\end{equation}
Finally, $\FPR_n = \FP_n / n$ is a \emph{scaled} transformation of the binomial distribution.
Thus, since $\FP_n = n \FPR_n$,
\begin{equation}
	\PDF{\fprateob_n \Given \fprate}[\FPR_n] = \PDF{n \fprateob}[\FP_n]\,.
\end{equation}
\end{proof}
The following corollary immediately follows.
\begin{corollary}
	\label{cor:tnbinom}
	Given $n$ negatives, the number of \emph{true negatives} in a random approximate set with a false positive rate $\fprate$ is a random variable denoted by $\TN_n$ with a distribution given by
	\begin{equation}
	\TN_n = n - \FP_n \sim \bindist\!\left(n, 1-\fprate\right)\,.
	\end{equation}
	By definition, the \emph{true negative rate} $\TNR_n = \TN_n / n = 1 - \FPR_n$.
\end{corollary}

By \cref{thm:fpr}, the more negatives there are, the lower the variance.
\begin{corollary}
\label{cor:fpr_as_vareps}
	Given \emph{countably infinite} negatives, a random approximate set with a false positive rate $\fprate$ is \emph{certain} to obtain $\fprate$.
\end{corollary}
\begin{proof}
We know that the \emph{expected} value for each of the random variables in this sequence is $\fprate$ and the variance is $\fprate(1-\fprate)/n$.
Immediately, we see that as $n$ increases, the distribution of false positives must become more concentrated around $\fprate$.
As $n \to \infty$, the variance goes to $0$, i.e., the distribution becomes degenerate with all of the probability mass assigned to the mean. See \cref{app:cor_fpr_as_vareps} for a more rigorous proof.
\end{proof}

The fewer negatives, the greater the variance.
The maximum possible variance, when $n=1$ and $\fprate = 0.5$, is $0.25$, may be used as the most \emph{pessimistic} estimate given a situation where we have no information about the false positive rate $\fprate$ and the cardinality of the universal set.

A degenerate case is given by letting $n = 0$, corresponding to a random approximate set of the universal set which has no negative elements that can be tested.
Respectively, only random \emph{negative} or \emph{positive} approximate sets may be generated for the universal set or empty set.

The number of false negatives is given by the following theorem.
\begin{theorem}
\label{thm:fnbinom}
Given $p$ positives, the uncertain number of \emph{false negatives} in random approximate sets with a false negative rate $\fnrate$ is modeled as a binomial distributed random variable denoted by $\FP_p$,
\begin{equation}
	\FN_p \sim \bindist(p, \fnrate)\,.
\end{equation}
\end{theorem}
\begin{proof}
By \cref{asm:fprate}, the probability that a positive element \emph{tests} as negative is $\fnrate$.
Thus, each test is a Bernoulli trial.
Since there are $p = \Card{\Set{S}}$ such independent and identically distributed trials with a probability of ``success'' $\fnrate$, the number of false negatives is binomially distributed.
\end{proof}

The false negative rate $\fnrate$ is an \emph{expectation}.
However, the false false negative rate of an approximate set $\ASet{S}$ parameterized by $\fnrate$ is \emph{uncertain}.
\begin{theorem}
\label{thm:fnr}
The false negative rate realizes an uncertain value as given by
\begin{equation}
    \FNR_p = \frac{\FN_p}{p}
\end{equation}
with a support $\SetBuilder{j / n}{j = 0,\ldots,p}$, an expectation 
$\fnrate$, 
and a variance $\fnrate(1-\fnrate) / p$.
\end{theorem}
The proof follows the same logic as the proof for \cref{thm:fpr}, except we 
replace \emph{negatives} with \emph{positives}.

In \cref{sec:set_theory}, we consider set-theoretic operations like 
\emph{complements}. The \emph{complement} operator applied to an approximate 
set 
of a set with countably infinite negatives is an approximate set of a set with 
countably infinite positives.
\begin{corollary}
An approximate set of a set with countably infinite positives has a false 
negative rate that is \emph{certain} to obtain $\fnrate$.
\end{corollary}
The proof follows the same logic as the proof for \cref{cor:fpr_as_vareps}, 
except we replace \emph{negatives} with \emph{positives}.

The number of true positives is given by the following corollary.
\begin{corollary}
\label{cor:tpbinom}
Given $p$ positives, the number of \emph{true positives} in an approximate set 
with a false negative rate $\fnrate$ is a random variable denoted by $\TP_p$
with a distribution given by 
\begin{equation}
    \TP_p \sim \bindist(p, \tprate)\,.
\end{equation}
By definition, the \emph{true positive rate} is given by $\TPR_p = 1 - 
\FNR_p$.
\end{corollary}
The proof follows the same logic as the proof for \cref{thm:fpr}.

Many other properties of random approximate sets follow from these distributions.
For instance, the distribution of $\Card{\ASet{A}[\fprate][\tprate]}$ given $p$ positives is
\begin{equation}
	\Card{\ASet{A}[\fprate][\tprate]} = \TP_p + \FP_{u - p}
\end{equation}
where $u$ is the cardinality of the universal set has an expectation of $(u - p) \fprate + p \tprate$ and variance of $(u - p) \fprate(1-\fprate) + p \tprate(1-\tprate)$, which is the generalization of the binomial distribution known as the \emph{Poisson binomial distribution}.

If we do not know the number of positives $p$, the cardinality $\Set{A}$, but have observed $\ASet{A}[\fprate][\tprate] = \Set{B}$, then $\Set{B}$ has a cardinality that tends to be centered around $u \fprate + p (\tprate - \fprate)$.
Solving for $p$ yields a method of moments estimator
\begin{equation}
	\widehat{p} = \frac{\Card{\Set{B}} - u \fprate}{\tprate - \fprate}\,.
\end{equation}
If the universal set $\Set{U}$ is infinite, then this estimator is undefined.

\subsection{Asymptotic limits}
\label{sec:asymtotic}
The false positive and false negative rates are a function of the cardinality of the objective and universal sets.
The limiting distributions for the false positive and true positive rates are given by the following theorems.
\begin{theorem}
    \label{thm:approxfpr}
    By \cref{thm:fpr}, the uncertain false positive rate $\FPR_n$ converges in
    distribution to the normal distribution with a mean $\fprate$ and a 
    variance $\fprate(1-\fprate)/n$, written
    \begin{equation}
    \label{eq:approxfpr}
	    \FPR_n \xrightarrow{d} \normdist(\fprate, \fprate(1-\fprate) / n)\,.
    \end{equation}
    Similarly, by \cref{cor:tpr}, the uncertain true positive rate of an approximate  set of $p$ positives, denoted by $\TPR_p$, converges in distribution to the normal distribution with a mean $\tprate$ and a variance $\tprate(1-\tprate)/p$, written
    \begin{equation}
    \label{eq:approxtpr}
    	\TPR_p \xrightarrow{d} \normdist(\tprate, \tprate(1-\tprate) / p)\,.
    \end{equation}
\end{theorem}
\begin{proof}
    By \cref{eq:proof_fpr_as_vareps} in the proof of \cref{cor:fpr_as_vareps}, 
    given 
    $n$ negatives, the false positive rate is
    \begin{equation}
    	\FPR_n = \frac{\RV{X_1}}{n} + \cdots + \frac{\RV{X_n}}{n}\,,
    \end{equation}
    where $\RV{X_1},\ldots,\RV{X_n}$ are $n$ independent Bernoulli trials each with a mean $\fprate$ and a variance $\fprate(1-\fprate)$.
    Therefore, by the central limit theorem, $\FPR_n$ converges in distribution to a normal distribution with a mean $\fprate$  and a variance $\fprate(1-\fprate)/n$.
    The proof for the true positive rate follows the same logic.
\end{proof}
By \cref{eq:approxfpr,eq:approxtpr},
\begin{equation}
	\TNR_n \xrightarrow{d} \normdist\!\left(1-\fprate, \fprate(1-\fprate) / n\right) \text{ and } \FNR_n \xrightarrow{d} \normdist\!\left(1-\tprate, \tprate(1-\tprate) / p\right)\,.	
\end{equation}

The random approximate set model is the \emph{maximum entropy} probability distribution for the indicated false positive and true positive rates, e.g., any estimated $\alpha$-confidence intervals are the largest intervals possible for the indicated $\alpha$ and therefore represent a worst-case uncertainty.

If we generate an approximate set, the uncertain false positive and true positive rates realize certain values, i.e., $\FPR_n = \fprateob$ and $\TPR_p = \tprateob$.
If the sample space is countably infinite, the distribution is degenerate, e.g., $\FPR_n = \fprate$ with probability $1$. 
However, for finite sample spaces, the outcomes are uncertain.
If these outcomes can be \emph{observed}, e.g., it is not too costly to compute, the exact values $\fprateob$ and $\tprateob$ may be recorded.
If these outcomes cannot be observed, e.g., it is too costly to compute or the information to compute $\fprateob$ or $\tprateob$ is not available, we may use the probabilistic model to inform us about the distribution of false positive rates.

\emph{Confidence intervals} that contain the true false positive rate $\fprateob$ and the true true positive rate $\tprateob$ are given by the following corollaries.
\begin{theorem}
    Given a random approximate set parameterized by $\fprate$ and $\tprate$, asymptotic $\alpha \cdot 100\%$ confidence intervals for the false positive rate and true positive rate are respectively
    \begin{equation}
    \label{eq:conf_fpr}
    \fprate \pm \sqrt{\frac{\fprate(1-\fprate)}{n}} \Phi^{-1}(\alpha/2)
    \end{equation}
    and
    \begin{equation}
    \label{eq:conf_tpr}
    \tprate \pm \sqrt{\frac{\tprate(1-\tprate)}{p}} \Phi^{-1}(\alpha/2)\,,
    \end{equation}
    where $\Phi^{-1} \colon [0,1] \mapsto \RealSet$ is the inverse cumulative distribution function of the standard normal.
\end{theorem}
As a worst-case (maximum uncertainty), we may let $n = p = 1$ in \cref{eq:conf_fpr,eq:conf_tpr}.
%However, if the universe is large and the objective sets are relatively small, a slightly optimistic confidence interval for $\fprate$ is provided by letting $n = \Card{\Set{U}}$.

\subsection{Other binary performance measures}
\label{sec:perf}
%\label{sec:func_rand_asets}
Suppose we have some other function $\Fun{g} \colon \PS{\Set{X}} \mapsto \Set{Y}$ that is not a \emph{constant}, then the composition $\Fun{g} \circ \APFun{id}[\fprate][\tprate]$ is some probability distribution over the codomain $\Set{Y}$.
That is, $\left(\Fun{g} \circ \APFun{id}[\fprate][\tprate]\right)(\Set{A})$ is a \emph{random variable}.
\begin{example}
	Let $\Fun{f} \colon \PS{\{0,1\}} \mapsto \{0,1\}$ be defined as
	\begin{equation}
	\Fun{f}(\Set{A}) \coloneqq
	\begin{cases}
	1 & \Set{A} \in \left\{\{1\},\{0,1\}\right\}\,,\\
	0 & \text{otherwise.}
	\end{cases}
	\end{equation}
	The composition $\Fun{f} \circ \APFun{id}[\mathsmaller{.25}][\mathsmaller{.75}]$ generates Bernoulli distribution random variables, e.g., $\left(\Fun{f} \circ \APFun{id}[\mathsmaller{.25}][\mathsmaller{.75}]\right)(\{0\}) \sim \berdist(0.25)$.
\end{example}

We consider several classes of functions and the distributions induced by replacing the inputs with random approximate sets, e.g., binary performance measures like positive predictive value.

% functions like subset or power set may be defined with respect to the member-of relation thus, the approximate member-of relation induces other kinds of approximate relations.

In the approximate set model, the distribution of random variables like the false positive, false negatives, true positives, and true negative rates are given respectively by parameters $\fprate$, $\fnrate$, $\tprate$, and $\tnrate$.
These parameters belong to a more general class of \emph{binary performance measures}.

The above parameters are statements about the distribution of random approximate sets given corresponding objective sets of interest, e.g.,
\begin{equation}
\Prob{\SetIndicator{\ASet{A}[\fprate][\tprate]}(x) \Given 
	\SetIndicator{\Set{A}}(x)} = \tprate\,.
\end{equation}

The accuracy of \emph{predictions} about objective sets given a corresponding approximate set is usually the more relevant performance measure.
The \emph{positive predictive value} is given by the following definition.
\begin{definition}
	The \emph{positive predictive value} is a performance measure defined as
	\begin{equation}
	\ppv = \frac{t_p}{t_p + f_p}
	\end{equation}
	where $t_p$ is the number of \emph{true positives} and $f_p$ is the number of \emph{false positives}.
\end{definition}

The positive predictive value of random approximate sets is a random variable given by the following theorem.
\begin{theorem}
	\label{thm:approx_expected_precision}
	Given $\n$ negatives, $\p$ positives, and a random approximate set with false positive and true positive rates $\fprate$ and $\tprate$ respectively, the \emph{positive predictive value} is a random variable
	\begin{equation}
	\PPV = \frac{\TP_{\p}}{\TP_{\p} + \FP_{\n}}
	\end{equation}
	with an \emph{expectation} given \emph{approximately} by
	\begin{equation}
	\label{eq:approx_expected_precision}
	\ppv(\tprate, \fprate, \p, \n) \approx 
	\frac{\overline{t}_\p}{\overline{t}_\p + \overline{f}_\p} +
	\frac{\overline{t}_\p \sigma_{\!f_\p}^2 - \overline{f}_\p 
		\sigma_{\!t_\p}^2}{\left(\overline{t}_\p + \overline{f}_\p\right)^3}\,,
	\end{equation}
	where $\overline{t}_\p = \p \tprate$ is the expected \emph{true positive} frequency, $\overline{f}_\p =  \n \fprate$ is the expected \emph{false positive} frequency, $\sigma_{\!t_\p}^2 = (1-\tprate) \overline{t}_\p$ is the variance of the \emph{true positive} frequency, and $\sigma_{\!f_\p}^2 = (1-\fprate) \overline{t}_\p$ is the variance of \emph{false positive} frequency.
\end{theorem}
See \cref{sec:proof_approx_expected_precision} for a proof of 
\cref{thm:approx_expected_precision}.

\begin{figure}
	\def\svgwidth{\columnwidth/2}
	%\def\svgscale{0.75}
	\centering
	\captionsetup{justification=centering}
	\caption
	{
		Relative frequency of positive predicitive values for several different parameterizations of the false positive and true positive rates given $\n = 900$ negatives and $\p=100$ positives.
	}    
	\input{img/out.pdf_tex}
	\label{fig:prec_vs_fprate_and_fnrate}
\end{figure}

We make the following observations about \cref{eq:approx_expected_precision}:
\begin{enumerate}
	\item For sufficiently large approximate sets, $\ppv \approx 
	\overline{t}_\p / (\overline{t}_\p + \overline{f}_\p)$.
	\item If $\fprate \neq 0$, as $\n \to \infty$, $\ppv \to 0$.
	\item As $\fprate \to 0$, $\ppv \to 1$.
\end{enumerate}

\emph{Accuracy} is given by the following definition.
\begin{definition}
	The \emph{accuracy} is the proportion of true results (both \emph{true 
		positives} and \emph{true negatives}) in the universe of positives and 
	negatives, $(t_p + t_n)/(\p + \n)$, where $t_p$, $t_n$, $\p$, and $\n$ are 
	respectively the number of \emph{true positives}, \emph{true negatives}, 
	\emph{positives}, and \emph{negatives}.
\end{definition}

The \emph{expected} accuracy is given by the following theorem.
\begin{theorem}
	\label{thm:approx_expected_accuracy}
	Given $\p$ positives and $\n$ negatives, a random approximate set with an 
	\emph{expected} false positive rate $\fprate$ and an \emph{expected} true 
	positive rate $\tprate$ is a random variable given by
	\begin{equation}
	\ACC_{\p + \n} = \lambda \TPR_\p + (1 - \lambda) \TNR_\n\,.
	\end{equation}	
	has an \emph{expected} accuracy
	\begin{equation}
	\label{eq:approx_expected_accuracy}
	\acc(\tprate,\fprate,\n,\p) = \lambda \tprate + (1-\lambda) \tnrate
	\end{equation}
	with a variance
	\begin{equation}
	\frac{\lambda \fnrate \tprate + (1 - \lambda)\fprate 
		\tnrate}{\p+\n}\,,   
	\end{equation}
	where $\lambda = \p / (\p + \n)$.
\end{theorem}
\begin{proof}
	Suppose there the $u$ elements in the universe can be partitioned into $\p$ 
	positives and $\n$ negatives. An approximate set $\ASet{S}$ with a false 
	positive rate $\fprate$ and false negative rate $\fnrate$ has an uncertain 
	accuracy
	\begin{equation}
	\ACC_{\p + \n} = \frac{\TP_\p + \TN_\n}{\p + \n}\,.
	\end{equation}
	The expected accuracy is given by the expectation
	\begin{align}
	\Expect{\ACC_{\p + \n}}
	&= \Expect{\frac{\TP_\p + \TN_\n}{\p + \n}}\\
	&= \frac{\p (1 - \fnrate) + \n (1 - \fprate)}{\p + \n}\,.
	\end{align}
	Noting that $\n/(\p+\n) = 1 - \p/(\p+\n)$ and letting $\lambda = \p/(\p + 
	\n)$,
	\begin{equation}
	\Expect{\ACC_{\p + \n}} = \lambda (1 - \fnrate) + (1 - \lambda) (1 - 
	\fprate)\,.
	\end{equation}
	The variance
	\begin{align}
	\Var{\ACC_{\p + \n}}
	&= \Var{\frac{\TP_\p}{\p + \n}} + \Var{\frac{\TN_\n}{\p + \n}}\\
	&= \frac{1}{(\p + \n)^2}\Var{\TP_\p} + \frac{1}{(\p + \n)^2}\Var{\TN_\n}\\
	&= \frac{\p \fnrate (1 - \fnrate)}{(\p + \n)^2} + \frac{\n \fprate (1 - 
		\fprate)}{(\p + \n)^2}\\
	&= \frac{\lambda \fnrate \tprate + (1 - \lambda)\fprate 
		\tnrate}{\p+\n}\,.
	\end{align}
\end{proof}

\emph{Negative predictive value} is given by the following definition.
\begin{definition}
	\begin{equation}
	\npv = \frac{t_n}{t_n + f_n}
	\end{equation}
	where $t_n$ and $f_n$ are respectively he number of \emph{true negatives} 
	and \emph{false negatives} 
\end{definition}
The expected negative predictive value is given by the following theorem.
\begin{theorem}
	\label{thm:npv_approx}
	Given $\p$ positives, $\n$ negatives, and a random approximate set with false positive and true positive rates $\fprate$ and $\tprate$ respectively, the negative predictive value is a \emph{random variable}
	\begin{equation}
	\NPV = \frac{\TN_{\n}}{\TN_{\n} + \FN_{\p}}
	\end{equation}
	with an \emph{expectation} given approximately by
	\begin{equation}
	\label{eq:npv_approx}
	\npv(\tprate, \fprate , \p, \n) \approx 
	\frac{\overline{t}_n}{\overline{t}_n + \overline{f}_{\!n}} +
	\frac{\overline{t}_n \sigma_{\!f_n}^2 - \overline{f}_{\!n} 
		\sigma_{\!t_n}^2}{\left(\overline{t}_n + \overline{f}_{\!n}\right)^3}\,,
	\end{equation}
	where $\overline{t}_\n = \n(1-\fprate)$ is the expected \emph{true negative} frequency, $\overline{f}_{\!\n} =  \p(1-\tprate)$ is the expected \emph{false negative} frequency, $\sigma_{\!t_\n}^2 = \fprate \overline{t}_\n$ is the variance of the \emph{true negative} frequency, and $\sigma_{\!f_\n}^2 = \tprate\overline{f}_{\!\n}$ is the variance of the \emph{false negative} frequency.
\end{theorem}
The proof for \cref{thm:npv_approx} follows the same pattern as the proof for \cref{thm:approx_expected_precision}.

Youden's $J$ statistic is a measure of the performance of a binary test, defined as
\begin{equation}
J = \frac{t_p}{t_p + f_n} + \frac{t_n}{t_n + f_p} - 1\,,
\end{equation}
with a range $[0,1]$.
In the case of the random approximate set model, $J$ is a random variable
\begin{equation}
\RV{J} = \TPR_\p - \FPR_\n\,,
\end{equation}
which has an \emph{expectation}
\begin{equation}
\Expect{\RV{J}} = \tprate - \fprate\,.
\end{equation}

\begin{table}
	\centering
	\caption{Various \emph{expected} performance measures.}
	\label{tbl:perf_sum}    
	\begin{tabular}{@{} l l l @{}}
		\toprule
		\textbf{measure} & \textbf{parameter} & \textbf{expected value}\\
		\midrule
		true positive rate & $\tpr(\tprate)$ & $\tprate$\\
		false positive rate & $\fpr(\fprate)$ & $\fprate$\\
		false negative rate & $\fnr(\tprate)$ & $1-\tprate$\\
		true negative rate & $\tnr(\fprate)$ & $1-\fprate$\\
		accuracy & $\acc$ & \cref{eq:approx_expected_accuracy}\\        
		positive predictive value & $\ppv$ & \cref{eq:approx_expected_precision}\\
		negative predictive value & $\npv$ & \cref{eq:npv_approx}\\        
		false discovery rate & $\fdr$ & $1-\ppv$\\
		false omission rate & $\forFn$ & $1-\npv$\\
		\bottomrule
	\end{tabular}
\end{table}
\Cref{tbl:perf_sum} may be used to reparameterize an approximate set.
\begin{example}
	Suppose we seek a \emph{positive approximate set} with an expected accuracy 
	$\gamma$. By \cref{tbl:perf_sum},
	\begin{equation}
	\gamma = \acc(\fprate,\fnrate=0,\lambda) = 1 - \fprate(1 - \lambda)\,.
	\end{equation}
	% Y = 1 - e(1- lam)
	% (1-Y)/(1-lam) = e
	Solving for $\fprate$ in terms of $\gamma$ yields the result
	\begin{equation}
	\fprate(\gamma, \lambda) = \frac{1 - \gamma}{1 - 
		\lambda}\
	\end{equation}
	subject to $0 \leq \lambda \leq \gamma \leq 1$ and $\lambda < 1$.
	Under this parameterization of the 	positive approximate set, $\lambda$ 
	must be known (or estimated).
	Note that if $\lambda = 1$ then $\fprate(\gamma, \lambda=1)$ is undefined as expected, but as $\lambda$ goes to $1$, $\fprate(\,\cdot\,; \lambda)$ goes to $1$ and $\gamma$ goes to $1$, which logically follows since if there are no negatives, there can be no false positives.
\end{example}

\end{document}