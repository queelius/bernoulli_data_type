{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"The concept of the random approximate data type (or value type) Random approximate set concept We provide two data types that model the concept of the random positive approximate set, the well-known Bloom filter and another data type that we call the approximate hash set. We also provide set-theoretic functions like union, complement, power set, Cartesian product, and disjoint union. We offer a mechanism such that any object that models a random approximate set over elements of type T may be type-erased as objects of type random_approximate_set<T> and set<T> (if the false positive and false negative queries are unnecessary). Finally, we provide a Boolean algebra query interface satisfies : (RandomApproximateSet<T>, BooleanQuery<T>) -> {True,False} , e.g., satisfies(s, not((a or b) and c)) , where s modes the concept of a random approximate set over type T , a,b,c are values of type T , and not , or , and and are Boolean queries, and the entire expression not((a or b) and c) is a Boolean query expression tree. For more on the random approximate set model, see https://github.com/queelius/random_approximate_set_model. Random approximate map concept The random approximate set over type T has a characteristic function that is a random approximate map over a domain of type T and a codomain of type Bool . Another name for a map is a partial function . Thus, a random approximate map is a generative model for partial functions whose domain of definition is uncertain. General purpose, space and time efficient generative models exist for representing any partial function over a finite domain of definition. Since a function, the expoential data type, can model many other data types, like lists, matrices, and so on, the random approximate map provides a facility for representing any random approximate data type. For instance, the random approximate set may be considered a special case of the random approximate map, i.e., its uncertain characteristic function as represented by a random approximate map. (Note that we have efficient data structures and algorithms that directly model the concept of a random approximate set, rather than using a random approximate map to represent its characteristic function.) Another example is an array of elements of type T which may be modeled as a function f : (N -> maybe T) , where f(i) represents the may be i -th element. If i is greater than or equal to the list's size, Nothing is returned.","title":"Home"},{"location":"#the-concept-of-the-random-approximate-data-type-or-value-type","text":"","title":"The concept of the random approximate data type (or value type)"},{"location":"#random-approximate-set-concept","text":"We provide two data types that model the concept of the random positive approximate set, the well-known Bloom filter and another data type that we call the approximate hash set. We also provide set-theoretic functions like union, complement, power set, Cartesian product, and disjoint union. We offer a mechanism such that any object that models a random approximate set over elements of type T may be type-erased as objects of type random_approximate_set<T> and set<T> (if the false positive and false negative queries are unnecessary). Finally, we provide a Boolean algebra query interface satisfies : (RandomApproximateSet<T>, BooleanQuery<T>) -> {True,False} , e.g., satisfies(s, not((a or b) and c)) , where s modes the concept of a random approximate set over type T , a,b,c are values of type T , and not , or , and and are Boolean queries, and the entire expression not((a or b) and c) is a Boolean query expression tree. For more on the random approximate set model, see https://github.com/queelius/random_approximate_set_model.","title":"Random approximate set concept"},{"location":"#random-approximate-map-concept","text":"The random approximate set over type T has a characteristic function that is a random approximate map over a domain of type T and a codomain of type Bool . Another name for a map is a partial function . Thus, a random approximate map is a generative model for partial functions whose domain of definition is uncertain. General purpose, space and time efficient generative models exist for representing any partial function over a finite domain of definition. Since a function, the expoential data type, can model many other data types, like lists, matrices, and so on, the random approximate map provides a facility for representing any random approximate data type. For instance, the random approximate set may be considered a special case of the random approximate map, i.e., its uncertain characteristic function as represented by a random approximate map. (Note that we have efficient data structures and algorithms that directly model the concept of a random approximate set, rather than using a random approximate map to represent its characteristic function.) Another example is an array of elements of type T which may be modeled as a function f : (N -> maybe T) , where f(i) represents the may be i -th element. If i is greater than or equal to the list's size, Nothing is returned.","title":"Random approximate map concept"},{"location":"BERNOULLI_ALGEBRAS/","text":"Random approximate alebras A random approximate algebra is a random approximate map with additional structure. A groupoid is... A monoid $$ (X,+,1) $$ is one of the simplest and useful algebraic structures. It defines a binary operation $$ + : X \\mapsto X \\mapsto X $$ where $+$ is associative and there exists an element $e$ such that $a + e = a$ for any $a in X$. If the random approximate map is *rate-distorted, for instance, then the identity $e$ cannot be guaranteed. However, if there is a total order on $X$, then $x (+) y$ can be defined as $$ x + y := \\begin{cases} x + y & x \\leq y\\ y + x & y < x. \\end{cases} $$ if $x < y$, $y + x$ can be converted to $x + y$ such that the commutative law (Abelian) is in the computational basis of random approximate maps (even if the values it maps have some non-zero loss). Alterantively, to try to minimize loss, if there is some function $$ avg : X \\mapsto X \\mapsto X $$ then $x (+) y$ can be defined as $$ x (+) y := avg(x + y, y + x), $$ which may reduce the expected loss on $(+)$ with respect to $+$, assuming that the random approximate commutative map $+$ attempted to map both $x$ to $y$ and $y$ to $x$. Of course, if the random approximate commutative map only attempted to map $x$ to $y$, $x < y$, with the understanding that it is Abelian and will convert $y + x$ to $x + y$, then this latter approach is expected to have more loss. However, the associative law cannot be guaranteed. For instance, given a set $X = {x_1,\\ldots,x_n$ and a total order $x_1 < x_2 \\ldots < x_n$. Then, $x_2 + x_3 + x_4 = x_2 + (x_3 + x_4)$ which may be computed as following: 1. Let $a = x_3 + x_4$. 2. If $a < x_2$, then the result is $a + x_2$ else $x_2 + a$. Alternatively, by the associative law, $x_2 + x_3 + x_4 = (x_2 + x_3) + x_4$, which may be computed as following: 1. Let $b = x_2 + x_3$. 2. If $b < x_4$, then the result is $b + x_4$ else $x_4 + b$. In the above, the first one neither computes $x_2 + x_3$ nor $the second one never computes $x_3 + x_4$, a We say that two tuples $x$ and $y$ are related by $R$ if $(x,y) \\in R$. Relations have many properties, like symmetry, reflectivity, transitivity, and other properties like being functional over some projection. We may re-use a concrete model of random approximate sets to construct models of random approximate relations. Many types or properties of relations are representable by random approximate relations, like symmetry and reflexivity, but many properties are not (efficiently) representable, like transitivity. We see that the random approximate relation model has a computational basis that is a subset of the relational model. For instance, random approximate binary symmetric relations are trivially representable by taking the symmetric closure of random approximate binary relations. For instance, given a binary relation $R := A x A$ and a total order $<= : A x A$, the symmetric closure of a binary relation $R := A x A$ may be obtained ordering $x,y in A$ such that, if $x < y$, $y R x$ is converted to $x R y$ (and $x R y$ is unchanged). If $R := A x B$, and we have isomorphisms $f : A \\mapsto C$ and $ g : B \\mapsto C$ with $<= : C x C$, then if $f x < f y$, $y R x$ is converted into $x R y$. NOPE... As approximate sets, approximate relations have the usual set-theoretic operations like complements and unions. They have additional operations, however, like selection, projection, and joins which have a different sorts of approximation errors. In additional to a Boolean algebra, relational properties provide additional query structure, like $a$ is between $b$ and $c$ if $(a,b,c) \\in B$ or $a$ is adjacent to $b$ if $a A b$. Other types of queries, with their own source of approximation error, may be constructed from these, e.g., we may approximate the relation $x_1 x_2 \\ldots x_n \\in S$, where $S$ represents 'is a sequence', with the adacent relation $A$ as follows: $x_1 x_2 \\ldots x_n$ is a sequence in $S$ if $x_1 A x_2$ and $x_2 A x_3$ and $\\ldots$ and $x_{n-1} A x_n$. For more on the random approximate set model, see https://github.com/queelius/random_approximate_relation_model. template struct retrn {}; template struct retrn<0> { bernoulli<0,T> operator()(T x) const { return bernoulli<0,T>{x}; } }; template struct retrn<1> { bernoulli<1,T> operator()(T x, double err) const { return bernoulli<1,T>{rate_interval {err},x}; } template <typename E> bernoulli<1,T> operator()(T x, rate_interval<E> err) const { return bernoulli<1,T>{err,x}; } }; // a Beroulli of a Bernoulli ... of a Bernoulli is a Bernoulli. template bernoulli join(bernoulli > x) { return join(x.value); } template bernoulli join(bernoulli x) { return x; }","title":"Algebra"},{"location":"BERNOULLI_ALGEBRAS/#random-approximate-alebras","text":"A random approximate algebra is a random approximate map with additional structure. A groupoid is... A monoid $$ (X,+,1) $$ is one of the simplest and useful algebraic structures. It defines a binary operation $$ + : X \\mapsto X \\mapsto X $$ where $+$ is associative and there exists an element $e$ such that $a + e = a$ for any $a in X$. If the random approximate map is *rate-distorted, for instance, then the identity $e$ cannot be guaranteed. However, if there is a total order on $X$, then $x (+) y$ can be defined as $$ x + y := \\begin{cases} x + y & x \\leq y\\ y + x & y < x. \\end{cases} $$ if $x < y$, $y + x$ can be converted to $x + y$ such that the commutative law (Abelian) is in the computational basis of random approximate maps (even if the values it maps have some non-zero loss). Alterantively, to try to minimize loss, if there is some function $$ avg : X \\mapsto X \\mapsto X $$ then $x (+) y$ can be defined as $$ x (+) y := avg(x + y, y + x), $$ which may reduce the expected loss on $(+)$ with respect to $+$, assuming that the random approximate commutative map $+$ attempted to map both $x$ to $y$ and $y$ to $x$. Of course, if the random approximate commutative map only attempted to map $x$ to $y$, $x < y$, with the understanding that it is Abelian and will convert $y + x$ to $x + y$, then this latter approach is expected to have more loss. However, the associative law cannot be guaranteed. For instance, given a set $X = {x_1,\\ldots,x_n$ and a total order $x_1 < x_2 \\ldots < x_n$. Then, $x_2 + x_3 + x_4 = x_2 + (x_3 + x_4)$ which may be computed as following: 1. Let $a = x_3 + x_4$. 2. If $a < x_2$, then the result is $a + x_2$ else $x_2 + a$. Alternatively, by the associative law, $x_2 + x_3 + x_4 = (x_2 + x_3) + x_4$, which may be computed as following: 1. Let $b = x_2 + x_3$. 2. If $b < x_4$, then the result is $b + x_4$ else $x_4 + b$. In the above, the first one neither computes $x_2 + x_3$ nor $the second one never computes $x_3 + x_4$, a We say that two tuples $x$ and $y$ are related by $R$ if $(x,y) \\in R$. Relations have many properties, like symmetry, reflectivity, transitivity, and other properties like being functional over some projection. We may re-use a concrete model of random approximate sets to construct models of random approximate relations. Many types or properties of relations are representable by random approximate relations, like symmetry and reflexivity, but many properties are not (efficiently) representable, like transitivity. We see that the random approximate relation model has a computational basis that is a subset of the relational model. For instance, random approximate binary symmetric relations are trivially representable by taking the symmetric closure of random approximate binary relations. For instance, given a binary relation $R := A x A$ and a total order $<= : A x A$, the symmetric closure of a binary relation $R := A x A$ may be obtained ordering $x,y in A$ such that, if $x < y$, $y R x$ is converted to $x R y$ (and $x R y$ is unchanged). If $R := A x B$, and we have isomorphisms $f : A \\mapsto C$ and $ g : B \\mapsto C$ with $<= : C x C$, then if $f x < f y$, $y R x$ is converted into $x R y$. NOPE... As approximate sets, approximate relations have the usual set-theoretic operations like complements and unions. They have additional operations, however, like selection, projection, and joins which have a different sorts of approximation errors. In additional to a Boolean algebra, relational properties provide additional query structure, like $a$ is between $b$ and $c$ if $(a,b,c) \\in B$ or $a$ is adjacent to $b$ if $a A b$. Other types of queries, with their own source of approximation error, may be constructed from these, e.g., we may approximate the relation $x_1 x_2 \\ldots x_n \\in S$, where $S$ represents 'is a sequence', with the adacent relation $A$ as follows: $x_1 x_2 \\ldots x_n$ is a sequence in $S$ if $x_1 A x_2$ and $x_2 A x_3$ and $\\ldots$ and $x_{n-1} A x_n$. For more on the random approximate set model, see https://github.com/queelius/random_approximate_relation_model. template struct retrn {}; template struct retrn<0> { bernoulli<0,T> operator()(T x) const { return bernoulli<0,T>{x}; } }; template struct retrn<1> { bernoulli<1,T> operator()(T x, double err) const { return bernoulli<1,T>{rate_interval {err},x}; } template <typename E> bernoulli<1,T> operator()(T x, rate_interval<E> err) const { return bernoulli<1,T>{err,x}; } }; // a Beroulli of a Bernoulli ... of a Bernoulli is a Bernoulli. template bernoulli join(bernoulli > x) { return join(x.value); } template bernoulli join(bernoulli x) { return x; }","title":"Random approximate alebras"},{"location":"BERNOULLI_ALGORITHM/","text":"Bernoulli algorithms Return a random element with a false positive rate k / N, where k is size of black list set and N is cardinality of domain. Randomly sample without replacement m of the k elements and returning the first sample with no collisions. The false positive rate is r = (k - m)/N, and the no-collision outcome is geometrically distributed with probability of no collision 1-r and thus there are expected to be 1/(1-r) trials. Bernoulli algorithm: is_sorted : bool* -> bernoulli<?,bool> Suppose we have a sequence of $n$ elements. If we want to determine if the sequence is sorted, we may do a single pass through the sequence, checking that $x_i \\leq x_{i+1}$ for $i=1,...,n-1$. However, $O(n)$ may be too slow for whatever reason. Alternatively, we could sample (without replacement) a subset and determine if the subset is sorted and use that information to estimate, with some probability of error, that the larger collection is sorted. Assume the sequence contains values sampled uniformly from a value type $X$. Say we have a sequence of $3$ Boolean values, $0$ or $1$, and we check the first two values for sortedness. What is the probability the sequence is sorted if we assume the Boolean values are sampled uniformly at random? There are $2^n = 2^4 = 16$ possible sequences over Boolean values. $$ { (0, 0, 0, 0), (0, 0, 0, 1), (0, 0, 1, 0), (0, 0, 1, 1),\\ (0, 1, 0, 0), (0, 1, 0, 1), (0, 1, 1, 0), (0, 1, 1, 1),\\ (1, 0, 0, 0), (1, 0, 0, 1), (1, 0, 1, 0), (1, 0, 1, 1),\\ (1, 1, 0, 0), (1, 1, 0, 1), (1, 1, 1, 0), (1, 1, 1, 1) }. $$ Of these, those that are in order, assuming $0 < 1$, are given by $$ { (0, 0, 0, 0), (0, 0, 0, 1), (0, 0, 1, 1),\\ (0, 1, 1, 1), (1, 1, 1, 1) }. $$ Case m=1 If we sample $m=1$, this is always sorted. Recall that we assume that the collection has elements sampled uniformly from $X := \\rm{Boolean}$. So, what is the probability that the larger collection is ordered? If we sampled a $0$, we look at all the ordered sub-samples that contain $0$ and then divide it by the total number of sub-samples that contain $0$. There are $4$ ordered sub-samples that contain $0$ and there are $15$ sub-samples that contain $0$, thus the probability that the collection is sorted is given by $4/15$. If we sampled a $1$, then we see there are $4$ ordered sub-samples that contain $1$ and $15$ sub-samples that contain $1$. Again, the probability comes out to $4/15$. In each case, the probability that $\\rm{is_sorted}$ outputs an erroneous value is $11/15$. This calls for a larger sample. Case m=2 If we sample $m=2$, what is the probability that the larger collection is ordered if the sample is ordered? The possible ordered sub-samples are given by $$ { (0,0),(0,1),(1,1) }. $$ If we sampled a $(0,0)$, we look at all the ordered sub-samples that contain $(0,0)$ and then divide it by the total number of sub-samples that contain $(0,0)$. There are $3$ ordered sub-samples that contain $(0,0)$ and there are $8$ sub-samples that contain $(0,0)$, thus the probability that the collection is sorted is given by $3/8$. If we sampled a $(0,1)$, then we see there are $3$ ordered sub-samples that contain $(0,1)$ and $11$ sub-samples that contain $(0,1)$, thus the probability that the collection is sorted is given by $3/11$. If we sampled a $(1,1)$, then we see there are $3$ ordered sub-samples that contain $(1,1)$ and $8$ sub-samples that contain $(1,1)$, thus the probability that the collection is sorted is given by $3/8$. The probability of error is still probably too large. Case m=3 If we sample $m=3$, what is the probability that the larger collection is ordered if the sample is ordered? The possible ordered sub-samples are given by $$ { (0,0,0),(0,0,1),(0,1,1),(1,1,1) }. $$ If we sampled a $(0,0,0)$, we look at all the ordered sub-samples that contain $(0,0,0)$ and then divide it by the total number of sub-samples that contain $(0,0,0)$. There are $2$ ordered sub-samples that contain $(0,0,0)$ and there are $3$ sub-samples that contain $(0,0,0)$, thus the probability that the collection is sorted is given by $2/3$. If we sampled a $(0,0,1)$, then we see there are $2$ ordered sub-samples that contain $(0,0,1)$ and $4$ sub-samples that contain $(0,0,1)$, thus the probability that the collection is sorted is given by $2/4=1/2$. If we sampled a $(0,1,1)$, then we see there are $2$ ordered sub-samples that contain $(1,1)$ and $4$ sub-samples that contain $(0,1,1)$, thus the probability that the collection is sorted is given by $3/8$. If we sampled a $(1,1,1)$, then we see there are $2$ ordered sub-samples that contain $(1,1,1)$ and $3$ sub-samples that contain $(1,1,1)$, thus the probability that the collection is sorted is given by $2/3$. The probability of error is still probably too large. However, if we sample $m=4$, the probability of error is $0$ since this reduces to the exact $\\rm{is_ordered}$ test function.","title":"Bernoulli algorithms"},{"location":"BERNOULLI_ALGORITHM/#bernoulli-algorithms","text":"Return a random element with a false positive rate k / N, where k is size of black list set and N is cardinality of domain. Randomly sample without replacement m of the k elements and returning the first sample with no collisions. The false positive rate is r = (k - m)/N, and the no-collision outcome is geometrically distributed with probability of no collision 1-r and thus there are expected to be 1/(1-r) trials.","title":"Bernoulli algorithms"},{"location":"BERNOULLI_ALGORITHM/#bernoulli-algorithm-is_sorted-bool-bernoullibool","text":"Suppose we have a sequence of $n$ elements. If we want to determine if the sequence is sorted, we may do a single pass through the sequence, checking that $x_i \\leq x_{i+1}$ for $i=1,...,n-1$. However, $O(n)$ may be too slow for whatever reason. Alternatively, we could sample (without replacement) a subset and determine if the subset is sorted and use that information to estimate, with some probability of error, that the larger collection is sorted. Assume the sequence contains values sampled uniformly from a value type $X$. Say we have a sequence of $3$ Boolean values, $0$ or $1$, and we check the first two values for sortedness. What is the probability the sequence is sorted if we assume the Boolean values are sampled uniformly at random? There are $2^n = 2^4 = 16$ possible sequences over Boolean values. $$ { (0, 0, 0, 0), (0, 0, 0, 1), (0, 0, 1, 0), (0, 0, 1, 1),\\ (0, 1, 0, 0), (0, 1, 0, 1), (0, 1, 1, 0), (0, 1, 1, 1),\\ (1, 0, 0, 0), (1, 0, 0, 1), (1, 0, 1, 0), (1, 0, 1, 1),\\ (1, 1, 0, 0), (1, 1, 0, 1), (1, 1, 1, 0), (1, 1, 1, 1) }. $$ Of these, those that are in order, assuming $0 < 1$, are given by $$ { (0, 0, 0, 0), (0, 0, 0, 1), (0, 0, 1, 1),\\ (0, 1, 1, 1), (1, 1, 1, 1) }. $$","title":"Bernoulli algorithm: is_sorted : bool* -&gt; bernoulli&lt;?,bool&gt;"},{"location":"BERNOULLI_ALGORITHM/#case-m1","text":"If we sample $m=1$, this is always sorted. Recall that we assume that the collection has elements sampled uniformly from $X := \\rm{Boolean}$. So, what is the probability that the larger collection is ordered? If we sampled a $0$, we look at all the ordered sub-samples that contain $0$ and then divide it by the total number of sub-samples that contain $0$. There are $4$ ordered sub-samples that contain $0$ and there are $15$ sub-samples that contain $0$, thus the probability that the collection is sorted is given by $4/15$. If we sampled a $1$, then we see there are $4$ ordered sub-samples that contain $1$ and $15$ sub-samples that contain $1$. Again, the probability comes out to $4/15$. In each case, the probability that $\\rm{is_sorted}$ outputs an erroneous value is $11/15$. This calls for a larger sample.","title":"Case m=1"},{"location":"BERNOULLI_ALGORITHM/#case-m2","text":"If we sample $m=2$, what is the probability that the larger collection is ordered if the sample is ordered? The possible ordered sub-samples are given by $$ { (0,0),(0,1),(1,1) }. $$ If we sampled a $(0,0)$, we look at all the ordered sub-samples that contain $(0,0)$ and then divide it by the total number of sub-samples that contain $(0,0)$. There are $3$ ordered sub-samples that contain $(0,0)$ and there are $8$ sub-samples that contain $(0,0)$, thus the probability that the collection is sorted is given by $3/8$. If we sampled a $(0,1)$, then we see there are $3$ ordered sub-samples that contain $(0,1)$ and $11$ sub-samples that contain $(0,1)$, thus the probability that the collection is sorted is given by $3/11$. If we sampled a $(1,1)$, then we see there are $3$ ordered sub-samples that contain $(1,1)$ and $8$ sub-samples that contain $(1,1)$, thus the probability that the collection is sorted is given by $3/8$. The probability of error is still probably too large.","title":"Case m=2"},{"location":"BERNOULLI_ALGORITHM/#case-m3","text":"If we sample $m=3$, what is the probability that the larger collection is ordered if the sample is ordered? The possible ordered sub-samples are given by $$ { (0,0,0),(0,0,1),(0,1,1),(1,1,1) }. $$ If we sampled a $(0,0,0)$, we look at all the ordered sub-samples that contain $(0,0,0)$ and then divide it by the total number of sub-samples that contain $(0,0,0)$. There are $2$ ordered sub-samples that contain $(0,0,0)$ and there are $3$ sub-samples that contain $(0,0,0)$, thus the probability that the collection is sorted is given by $2/3$. If we sampled a $(0,0,1)$, then we see there are $2$ ordered sub-samples that contain $(0,0,1)$ and $4$ sub-samples that contain $(0,0,1)$, thus the probability that the collection is sorted is given by $2/4=1/2$. If we sampled a $(0,1,1)$, then we see there are $2$ ordered sub-samples that contain $(1,1)$ and $4$ sub-samples that contain $(0,1,1)$, thus the probability that the collection is sorted is given by $3/8$. If we sampled a $(1,1,1)$, then we see there are $2$ ordered sub-samples that contain $(1,1,1)$ and $3$ sub-samples that contain $(1,1,1)$, thus the probability that the collection is sorted is given by $2/3$. The probability of error is still probably too large. However, if we sample $m=4$, the probability of error is $0$ since this reduces to the exact $\\rm{is_ordered}$ test function.","title":"Case m=3"},{"location":"BERNOULLI_RELATION/","text":"Random approximate relations A random approximate relation is a random approximate set with additional structure between tuples of elements in the set. We say that two tuples $x$ and $y$ are related by $R$ if $(x,y) \\in R$. Relations have many properties, like symmetry, reflectivity, transitivity, and other properties like being functional over some projection. We may re-use a concrete model of random approximate sets to construct models of random approximate relations. Many types or properties of relations are representable by random approximate relations, like symmetry and reflexivity, but many properties are not (efficiently) representable, like transitivity. We see that the random approximate relation model has a computational basis that is a subset of the relational model. For instance, random approximate binary symmetric relations are trivially representable by taking the symmetric closure of random approximate binary relations. For instance, given a binary relation $R := A x A$ and a total order $<= : A x A$, the symmetric closure of a binary relation $R := A x A$ may be obtained ordering $x,y in A$ such that, if $x < y$, $y R x$ is converted to $x R y$ (and $x R y$ is unchanged). If $R := A x B$, and we have isomorphisms $f : A -> C$ and $ g : B -> C$ with $<= : C x C$, then if $f x < f y$, $y R x$ is converted into $x R y$. NOPE... As approximate sets, approximate relations have the usual set-theoretic operations like complements and unions. They have additional operations, however, like selection, projection, and joins which have a different sorts of approximation errors. In additional to a Boolean algebra, relational properties provide additional query structure, like $a$ is between $b$ and $c$ if $(a,b,c) \\in B$ or $a$ is adjacent to $b$ if $a A b$. Other types of queries, with their own source of approximation error, may be constructed from these, e.g., we may approximate the relation $x_1 x_2 \\ldots x_n \\in S$, where $S$ represents 'is a sequence', with the adacent relation $A$ as follows: $x_1 x_2 \\ldots x_n$ is a sequence in $S$ if $x_1 A x_2$ and $x_2 A x_3$ and $\\ldots$ and $x_{n-1} A x_n$. For more on the random approximate set model, see https://github.com/queelius/random_approximate_relation_model.","title":"Relation"},{"location":"BERNOULLI_RELATION/#random-approximate-relations","text":"A random approximate relation is a random approximate set with additional structure between tuples of elements in the set. We say that two tuples $x$ and $y$ are related by $R$ if $(x,y) \\in R$. Relations have many properties, like symmetry, reflectivity, transitivity, and other properties like being functional over some projection. We may re-use a concrete model of random approximate sets to construct models of random approximate relations. Many types or properties of relations are representable by random approximate relations, like symmetry and reflexivity, but many properties are not (efficiently) representable, like transitivity. We see that the random approximate relation model has a computational basis that is a subset of the relational model. For instance, random approximate binary symmetric relations are trivially representable by taking the symmetric closure of random approximate binary relations. For instance, given a binary relation $R := A x A$ and a total order $<= : A x A$, the symmetric closure of a binary relation $R := A x A$ may be obtained ordering $x,y in A$ such that, if $x < y$, $y R x$ is converted to $x R y$ (and $x R y$ is unchanged). If $R := A x B$, and we have isomorphisms $f : A -> C$ and $ g : B -> C$ with $<= : C x C$, then if $f x < f y$, $y R x$ is converted into $x R y$. NOPE... As approximate sets, approximate relations have the usual set-theoretic operations like complements and unions. They have additional operations, however, like selection, projection, and joins which have a different sorts of approximation errors. In additional to a Boolean algebra, relational properties provide additional query structure, like $a$ is between $b$ and $c$ if $(a,b,c) \\in B$ or $a$ is adjacent to $b$ if $a A b$. Other types of queries, with their own source of approximation error, may be constructed from these, e.g., we may approximate the relation $x_1 x_2 \\ldots x_n \\in S$, where $S$ represents 'is a sequence', with the adacent relation $A$ as follows: $x_1 x_2 \\ldots x_n$ is a sequence in $S$ if $x_1 A x_2$ and $x_2 A x_3$ and $\\ldots$ and $x_{n-1} A x_n$. For more on the random approximate set model, see https://github.com/queelius/random_approximate_relation_model.","title":"Random approximate relations"},{"location":"NORMAL_FORMS/","text":"Types We say that a tick, ' , followed by a sequence of alphabetic symbols is an Atom , i.e., 'a and 'b are Atoms but a is not. We say that the type of 'a is an Atom . Suppose we say that a Pair begins with cons and ends with two more parts, its car and its cdr . So, cons 'a 'b is a (Pair Atom Atom) (that is its type) and cdr (cons 'a 'b) is the same Atom as 'b . Sentences like \" 'a is an Atom \", \" cons 'a 'b' is a (Pair Atom Atom) are judgements -- that is, attitudes that people take towards expressions. Another judgement is \" cons 'a 'b is the same (Pair Atom Atom) as cons 'a b' \". However, cons 'a 'b is not the same Atom as cons 'b 'a . For two (Pair Atom Atom) to be the same, they must have the same car and cdr . It must also be true that cons 'a 'b' is the same (Pair Atom Atom) as car (cons (cons 'a 'b) 'c) , but cons 'a 'b' is a simpler expression. Given the set of expressions that are the same Atoms as 'a , the simplest expression is its normal form, which is just 'a . Normal Forms Definition: Given a type, every expression described by that type has a normal form, which is the most direct way of writing it. If two expressions are the same, then they have identical normal forms, and if they have identical normal forms, then they are the same. In a random approximate set over a countably infinite universe, representational equality implies equality and equality implies representational equality. This is true even when we take unions, intersections, and complements of random approximate sets, i.e., two such compositions are equal iff, when we reduce both compositions to, say, disjunctive normal form, they are the same if they have the same disjunctive normal form and each term (random approximate set) has the same representation. This has the interesting property that the normal form is provided by the disjunctive (or conjunctive) normal form over the random approximate sets with some canonical ordering, e.g., lexographic order on the serialization of the composed random approximate infinite sets. For finite universal sets, the normal form of a random approximate set is just the elements in the set, since we can enumerate each of them. If enumerate is not practical, then we may reduce them to disjunctive normal form and do the equality comparisons on each of the operations and terms. However, in this case, while representational equality implies equality, equality does not imply representational equality since there are many ways to represent the same set. In fact, there are many ways to represent the same infinite set too, but since the nature of the random approximate set is presumably random, ... There are four basic forms of judgement: _ is a _. _ is the same _ as _. _ is a type. _ and _ are the same type. There may be many ways to say the same thing.","title":"Normal form"},{"location":"NORMAL_FORMS/#types","text":"We say that a tick, ' , followed by a sequence of alphabetic symbols is an Atom , i.e., 'a and 'b are Atoms but a is not. We say that the type of 'a is an Atom . Suppose we say that a Pair begins with cons and ends with two more parts, its car and its cdr . So, cons 'a 'b is a (Pair Atom Atom) (that is its type) and cdr (cons 'a 'b) is the same Atom as 'b . Sentences like \" 'a is an Atom \", \" cons 'a 'b' is a (Pair Atom Atom) are judgements -- that is, attitudes that people take towards expressions. Another judgement is \" cons 'a 'b is the same (Pair Atom Atom) as cons 'a b' \". However, cons 'a 'b is not the same Atom as cons 'b 'a . For two (Pair Atom Atom) to be the same, they must have the same car and cdr . It must also be true that cons 'a 'b' is the same (Pair Atom Atom) as car (cons (cons 'a 'b) 'c) , but cons 'a 'b' is a simpler expression. Given the set of expressions that are the same Atoms as 'a , the simplest expression is its normal form, which is just 'a .","title":"Types"},{"location":"NORMAL_FORMS/#normal-forms","text":"Definition: Given a type, every expression described by that type has a normal form, which is the most direct way of writing it. If two expressions are the same, then they have identical normal forms, and if they have identical normal forms, then they are the same. In a random approximate set over a countably infinite universe, representational equality implies equality and equality implies representational equality. This is true even when we take unions, intersections, and complements of random approximate sets, i.e., two such compositions are equal iff, when we reduce both compositions to, say, disjunctive normal form, they are the same if they have the same disjunctive normal form and each term (random approximate set) has the same representation. This has the interesting property that the normal form is provided by the disjunctive (or conjunctive) normal form over the random approximate sets with some canonical ordering, e.g., lexographic order on the serialization of the composed random approximate infinite sets. For finite universal sets, the normal form of a random approximate set is just the elements in the set, since we can enumerate each of them. If enumerate is not practical, then we may reduce them to disjunctive normal form and do the equality comparisons on each of the operations and terms. However, in this case, while representational equality implies equality, equality does not imply representational equality since there are many ways to represent the same set. In fact, there are many ways to represent the same infinite set too, but since the nature of the random approximate set is presumably random, ... There are four basic forms of judgement: _ is a _. _ is the same _ as _. _ is a type. _ and _ are the same type. There may be many ways to say the same thing.","title":"Normal Forms"},{"location":"NUMBER_TYPE/","text":"Approximate number types Assuming $T$ models a numerical type $R$ where $T$ has $n$ digits of precision and $R$ has $N$ digits of precision, $n < N$, then $$ == : (T,T) -> bool $$ is an approximation of $$ == : (R,R) -> bool $$ since, the mapping from $R$ to $T$ must be non-injective, i.e., at least two values in $R$ map to the same value in $T$. Depending on how $T$ represents $R$, there may be variability in the approximation error over the values in $R$. Suppose $R$ represents numbers as a sequence of $N$ bits, where the $k$-th most significant bit is the $k$-th element of the sequence. Then, if $T$ models numbers in the same way, except with $n$ bit sequences where $n < N$, then the mapping from $R$ to $T$ that results in the smallest uniform error is given by keeping the first $n$ bits of the sequence. If we do this, the error is bounded by $$ [0,2^(N-n)]. $$ If we only wish to view this as a Bernoulli approximation, then $$ P[T(X) == R(X) | X ~ UNIF(R)] = 2^-(N-n) $$ where $UNIF(R)$ is the discrete uniform distribution over $R$. If $R$ is an infinite set, like the real numbers, then $T$, as a finite precision representation, can only exactly model a finite number of numbers on the order of $O(2^n)$ and the probability $P[T(X) == R(X)]$ is zero unless we assign non-zero probability to specific values of $X$ in the domain of $T$.","title":"Numbers"},{"location":"NUMBER_TYPE/#approximate-number-types","text":"Assuming $T$ models a numerical type $R$ where $T$ has $n$ digits of precision and $R$ has $N$ digits of precision, $n < N$, then $$ == : (T,T) -> bool $$ is an approximation of $$ == : (R,R) -> bool $$ since, the mapping from $R$ to $T$ must be non-injective, i.e., at least two values in $R$ map to the same value in $T$. Depending on how $T$ represents $R$, there may be variability in the approximation error over the values in $R$. Suppose $R$ represents numbers as a sequence of $N$ bits, where the $k$-th most significant bit is the $k$-th element of the sequence. Then, if $T$ models numbers in the same way, except with $n$ bit sequences where $n < N$, then the mapping from $R$ to $T$ that results in the smallest uniform error is given by keeping the first $n$ bits of the sequence. If we do this, the error is bounded by $$ [0,2^(N-n)]. $$ If we only wish to view this as a Bernoulli approximation, then $$ P[T(X) == R(X) | X ~ UNIF(R)] = 2^-(N-n) $$ where $UNIF(R)$ is the discrete uniform distribution over $R$. If $R$ is an infinite set, like the real numbers, then $T$, as a finite precision representation, can only exactly model a finite number of numbers on the order of $O(2^n)$ and the probability $P[T(X) == R(X)]$ is zero unless we assign non-zero probability to specific values of $X$ in the domain of $T$.","title":"Approximate number types"},{"location":"PHF/","text":"Perfect hash filter (PHF) The perfect hash filter (PHF) is a rate-distorted (frozen) set that models the second-order Bernoulli type over 2^X. It is implemented by composing a perfect hash function, or a rate-distorted perfect hash function, a vector of hashes, a bit matrix, and a codec.","title":"Perfect hash filter"},{"location":"PHF/#perfect-hash-filter-phf","text":"The perfect hash filter (PHF) is a rate-distorted (frozen) set that models the second-order Bernoulli type over 2^X. It is implemented by composing a perfect hash function, or a rate-distorted perfect hash function, a vector of hashes, a bit matrix, and a codec.","title":"Perfect hash filter (PHF)"},{"location":"VALUE/","text":"Readme Suppose we have some type constructor + : Type -> Type -> Type such that A+B is a type that has as values the disjoint union of the elements in A and B. Suppose we have a function not : {0} + {1} -> {0} + {1} defined as not 0 := 1, not 1 := 0. Suppose we have an prefix-free coder for {0}+{1} given by enc(0) := {11} enc(0) := {0,10}, which are optimal codes if the probability masses are P(0) = 1/4, P(1) = 3/4. Suppose we have a first-order random approximate type of {0}+{1}, where P[not(1) == 0] = 1-r, P[not(1) == 1] = r where r is some rate distortion or noise.","title":"Values"},{"location":"VALUE/#readme","text":"Suppose we have some type constructor + : Type -> Type -> Type such that A+B is a type that has as values the disjoint union of the elements in A and B. Suppose we have a function not : {0} + {1} -> {0} + {1} defined as not 0 := 1, not 1 := 0. Suppose we have an prefix-free coder for {0}+{1} given by enc(0) := {11} enc(0) := {0,10}, which are optimal codes if the probability masses are P(0) = 1/4, P(1) = 3/4. Suppose we have a first-order random approximate type of {0}+{1}, where P[not(1) == 0] = 1-r, P[not(1) == 1] = r where r is some rate distortion or noise.","title":"Readme"}]}