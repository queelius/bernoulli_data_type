<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Bernoulli Data Type: The Bernoulli Model: A Closer Look at the Boolean Bernoulli Model</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Bernoulli Data Type
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('md_BERNOULLI_BOOL.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">The Bernoulli Model: A Closer Look at the Boolean Bernoulli Model </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>The Boolean type, represented as <code>bool</code> in C++, models the set of values given by <code>{true,false}</code>. This document entertains the replacement of <code>bool</code> with a type <code>bernoulli&lt;bool&gt;</code>, which represents a sort of <em>noisy</em> Boolean. In general, we can have a Bernoulli type for any type <code>T</code>, denoed by <code>bernoulli&lt;T&gt;</code>.</p>
<p>Each Bernoulli Model also has an <em>order</em>, an integer greater than 1, and it essentially describes the number of independent ways in which the process that generated the Bernoulli approximation can produce errors. We denote that a Bernoulli Model has order <code>K</code> with <code>bernoulli&lt;T,K&gt;</code>. Unless it is useful, we drop the order information and simply write <code>bernoulli&lt;T&gt;</code>.</p>
<blockquote class="doxtable">
<p>As special case, data structures like Bloom filters can be thought of as a Bernoulli data structure. </p>
</blockquote>
<p>In the Bernoulli Boolean model, a <code>bool</code> is wrapped inside of a Bernoulli type <code>bernoulli&lt;bool&gt;</code>. We use the notation <code>bernoulli&lt;bool&gt;{x}</code> to denote that it is modeling some <em>latent</em> variable <code>x</code> (unobservable). We can think of <code>bernoulli&lt;bool&gt;{x}</code> as a measurement of <code>x</code>, or a noisy version of the original <code>x</code>, and it may or may not equal <code>x</code>.</p>
<p>The Bernoulli model introduces a notion of uncertainty or error. Specifically, a <code>bernoulli&lt;bool&gt;{x}</code> is a <em>random Bernoulli variable</em> such that </p><div class="fragment"><div class="line">Pr{bernoulli&lt;bool&gt;{x} == x} == p(x)</div>
</div><!-- fragment --><p> where <code>0 &lt; p(x) &lt; 1</code> is the probability of being correct and <code>1-p(x)</code> is the probability of an error. In most practical situations, the probability <code>p(x)</code> is known and can be adjusted to balance factors like space and accuracy.</p>
<h1><a class="anchor" id="autotoc_md1"></a>
Motivation</h1>
<p>A big reason for developing the Bernoulli Model formalism is so that we can use Bernoulli Models of data types to develop Oblivious Data Types. We will go into that in a separate document, but the basic idea is that Bernoulli approximations have a lot of desirable properties for developing oblivious data types, and the Bernoulli Model formalism allows us to reason about the correctness of the oblivious data types and to make them more space-efficient by trading accuracy for space while allowing for <code>O(1)</code> time complexity.</p>
<p>The Bernoulli Model also provides a formalism for how to think about various probabilistic data structures, like the Bloom filter, Count-Min sketch, or my invention, the Bernoulli data type, which comprises an entire family of data structures that are all based on the Bernoulli Model, from sets (like the Bloom filter) to maps in a near-space optimal way, while allowing for more savings by trading accuracy for space in a controlled way.</p>
<p>In this paper, we narrow our focus to the Boolean Bernoulli Model, which is the simplest Bernoulli Model. Later in this document, we consider Bernoulli Models for Boolean functions too, since it provides a natural opportunity to think about the model in a more general way.</p>
<h1><a class="anchor" id="autotoc_md2"></a>
Binary Channels</h1>
<p>Let's begin by thinking about the Binary Symmetric Channel and the Binary Asymmetric Channel. The Bernoulli Boolean model can exhibit two distinct behaviors, represented as different "channels" through which Boolean values are transmitted:</p>
<ol type="1">
<li><b>Binary Symmetric Channel (First-order Bernoulli model)</b>: The probability of an equality error is the same for <code>true</code> and <code>false</code>. We denote this by the type <code>bernoulli&lt;bool,1&gt;</code>.</li>
<li><b>Binary Asymmetric Channel (Second-order Bernoulli model)</b>: The probability of an equality error differs for <code>true</code> and <code>false</code>. We denote this by the type <code>bernoulli&lt;bool,2&gt;</code>.</li>
</ol>
<h1><a class="anchor" id="autotoc_md3"></a>
False Positives and Negatives</h1>
<p>Errors in the Bernoulli Boolean model can be understood in terms of <em>false negatives</em> and <em>false positives</em>:</p>
<ol type="1">
<li><code>bernoulli&lt;bool&gt;{false} == true</code> is a <em>false negative</em>.</li>
<li><code>bernoulli&lt;bool&gt;{true} == false</code> is a <em>false positive</em>.</li>
</ol>
<p>In the first-order model, the probability of a false negative equals the probability of a false positive. In the second-order model, these probabilities differ. In a specific but common version of the second-order Bernoulli Boolean model, false negatives occur with probability 0 and false positives occur with probability <code>0 &lt; \varepsilon &lt; 1</code>.</p>
<h1><a class="anchor" id="autotoc_md4"></a>
Prediction</h1>
<p><code>bernoulli&lt;bool&gt;{x}</code> is <em>correlated</em> with <code>x</code>, and ideally, <code>bernoulli&lt;bool&gt;{x}</code> provides evidence for <code>x</code>, i.e., allows one to predict <code>x</code> given <code>bernoulli&lt;bool&gt;{x}</code> better than if no observations where given whatsoever. If the probability of correct <code>p(x)</code> is <code>&lt;= 0.5</code> and we have no prior information about <code>x</code>, the best (ML) estimate of <code>x</code> is the observation <code>bernoulli&lt;bool&gt;{x}</code>.</p>
<p>However, with prior information about <code>x</code>, we can estimate the probability that the latent variable <code>x</code> is <code>true</code> or <code>false</code>. Using Bayes' rule, the probability that <code>bernoulli&lt;bool&gt;{x}</code> is correct is:</p>
<div class="fragment"><div class="line">Pr{x == <span class="keyword">true</span> | bernoulli&lt;bool&gt;{x} == <span class="keyword">true</span>} ==</div>
<div class="line">    Pr{bernoulli&lt;bool&gt;{x} == <span class="keyword">true</span> | x == <span class="keyword">true</span> } * Pr{x == <span class="keyword">true</span>}</div>
<div class="line">    /</div>
<div class="line">    (Pr{bernoulli&lt;bool&gt;{x} == <span class="keyword">true</span> | x == <span class="keyword">true</span>} * Pr{x == <span class="keyword">true</span>} +</div>
<div class="line">    Pr{bernoulli&lt;bool&gt;{x} == <span class="keyword">true</span> | x == <span class="keyword">false</span>} * (1-Pr{x == <span class="keyword">true</span>}))</div>
</div><!-- fragment --><p>In the first-order model, if the probability of being correct <code>q</code>, then: </p><div class="fragment"><div class="line">Pr{x == <span class="keyword">true</span> | bernoulli&lt;bool,1&gt;{x} == <span class="keyword">true</span>} ==</div>
<div class="line">    q * Pr{x == <span class="keyword">true</span>}</div>
<div class="line">    /</div>
<div class="line">    (q * Pr{x == <span class="keyword">true</span>} + (1-q) * (1-Pr{x == <span class="keyword">true</span>}))</div>
</div><!-- fragment --><p>Assuming maximum ignorance (maximum entropy) about <code>x</code> (i.e., <code>Pr{x == true} == 0.5</code>), the following expression is obtained: </p><div class="fragment"><div class="line">Pr{x == <span class="keyword">true</span> | bernoulli&lt;bool,1&gt;{x} == <span class="keyword">true</span>} == q</div>
</div><!-- fragment --><p>One could even imagine having multiple sources of, say, noisy i.i.d. measurements of the same <code>x</code>. For instance, suppose <code>x == true</code> but we don't know that and we have <code>3</code> measurements of <code>x</code>. </p><div class="fragment"><div class="line">y1 = bernoulli&lt;bool,1&gt;{<span class="keyword">true</span>} == <span class="keyword">true</span></div>
<div class="line">y2 = bernoulli&lt;bool,1&gt;{<span class="keyword">true</span>} == <span class="keyword">false</span></div>
<div class="line">y3 = bernoulli&lt;bool,1&gt;{<span class="keyword">true</span>} == <span class="keyword">true</span></div>
</div><!-- fragment --><p>This is more information about <code>x</code> than just one noisy observation. Clearly, and informally, the best prediction for the value of <code>x</code> is the majority vote, which is <code>true</code> in this case.</p>
<p>Consider this. The number of <code>true</code> values is Binomially distributed with parameters <code>n=3</code> (independent trials) and probability <code>p</code>, so we let <code>N ~ BIN(3,p)</code> denote the random variable representing the number of <code>true</code> values in <code>y1, y2, y3</code>.</p>
<p>Let's do a case by case analysis to compute the probability that the above majority vote is correct. First, for the majority vote to be correct, <code>N &gt;= 2</code>, which means that <code>N == 2</code> or <code>N == 3</code>.</p>
<ol type="1">
<li>The probability that <code>N == 2</code> is <code>Pr{N == 2} = 3 * p^2 * (1-p)</code>.</li>
<li>The probability that <code>N == 3</code> is <code>Pr{N == 3} = p^3</code>.</li>
</ol>
<p>Therefore, the probability of no error is <code>3 * p^2 * (1-p) + p^3</code>. If <code>p = 0.5</code> (maximum ignorance), we get a no error rate of <code>0.5</code>, as intuitively expected. For <code>p = 1</code>, we get a no error rate of <code>1</code>, which is also intuitively expected. The no error rate of a single observation, of course, is just <code>p</code>. Let's plot these two no error rates together:</p>
<p><img src="plot_maj_vote.png" alt="test" class="inline"/></p>
<p>We see a slight improvement in the no error rate when we have multiple noisy observations of the same latent variable. As the number of independent sources goes to infinity, the error rate goes to 0.</p>
<p>This is not a typical use-case for the Bernoulli Boolean model, since it will mostly be a analytical result of probabilistic data structures that may be framed in the context of a Bernoulli model, but it is interesting to see how the model behaves in this case.</p>
<h1><a class="anchor" id="autotoc_md5"></a>
Inducing Bernoulli types</h1>
<p>If we have a function <code>f : bool -&gt; bool</code>, then the space of all possible functions is given by Table 1.</p>
<p>Table 1: All possible functions <code>f : bool -&gt; bool</code></p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">f   </th><th class="markdownTableHeadNone">f(true)   </th><th class="markdownTableHeadNone">f(false)    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">id   </td><td class="markdownTableBodyNone">true   </td><td class="markdownTableBodyNone">false    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">not   </td><td class="markdownTableBodyNone">false   </td><td class="markdownTableBodyNone">true    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">true   </td><td class="markdownTableBodyNone">true   </td><td class="markdownTableBodyNone">true    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">false   </td><td class="markdownTableBodyNone">false   </td><td class="markdownTableBodyNone">false   </td></tr>
</table>
<p>It may be interesting to consider what happens when we replace the Boolean inputs with Bernoulli boolean values and ask the question, "What is the probability that
`f(bernoulli&lt;bool,1&gt;{x}) == f(x)`?"</p>
<p>Notice that <code>f(bernoulli&lt;bool,1&gt;{x})</code> is <code>f(x)</code> with some probability, but <code>f(x)</code> may be latent depending on <code>f</code>. For the constant fuctions, <code>true</code> and <code>false</code>, we get the same function, i.e., <code>true(bernoulli&lt;bool,1&gt;{true}) == true</code> since <code>true : bool -&gt; bool</code> always outputs <code>true</code>, and similiarly for <code>false : bool -&gt; bool</code>.</p>
<p>However, the <code>id</code> and <code>not</code> functions are different. For instance, suppose <code>Pr{bernoulli&lt;bool,1&gt;{x} == x} == p</code>. Then, when we input <code>bernoulli&lt;bool,1&gt;{true}</code> into <code>id</code>, we get the correct output <code>true</code> with probability <code>p</code> and the incorrect output <code>false</code> with probability <code>1-p</code>. Likewise, when we input <code>bernoulli&lt;bool,1&gt;{false}</code> into <code>id</code>, we get the correct output <code>id(true) == false</code> with probability <code>p</code> and the incorrect output <code>f(false) == true</code> with probability <code>1-p</code>, and a similar story for <code>not</code>.</p>
<p>Since we can think of these outputs as either correct or incorrect with probability <code>p</code>, we can call them Bernoulli Boolean values too, e.g., this is a function of type </p><div class="fragment"><div class="line">bernoulli&lt;bool,1&gt; -&gt; bernoulli&lt;bool,1&gt;</div>
</div><!-- fragment --><p>What is this function? It's just <code>id</code>, but it has been monadically lifted into the Bernoulli Boolean model. Notice also that this is distinct from the type </p><div class="fragment"><div class="line"><span class="keywordtype">bool</span> -&gt; bernoulli&lt;bool,1&gt;</div>
</div><!-- fragment --><p> which is what we say is a Bernoulli map from <code>bool</code> to <code>bernoulli&lt;bool,1&gt;</code>. In this case, it is a first-order Bournoulli map on the equality of its output, i.e., </p><div class="fragment"><div class="line">Pr{bernoulli&lt;<span class="keywordtype">bool</span> -&gt; bool,1&gt;{<span class="keywordtype">id</span>}(x) == <span class="keywordtype">id</span>(x)} == p</div>
</div><!-- fragment --><p>Notice what the notation suggests, too. We are writing <code>bernoulli&lt;bool -&gt; bool,1&gt;{id}</code> to indicate that the true value is <code>id</code> but what we <em>observe</em> is <code>bernoulli&lt;bool-&gt;bool,1&gt;{id}</code>. We cannot observe <code>id</code> directly. In fact, if we knew it was the identity function, we already know the correct output. We are interested in the case where we don't know the correct output, and all we are given as evidence is the observation <code>bernoulli&lt;bool-&gt;bool,1&gt;{id}</code>.</p>
<p>So, we are applying the <code>bernoulli</code> concept to the function type <code>bool -&gt; bool</code>, which in this case only has 4 possibilities. Clearly, we normally would <em>not</em> use a Bernoulli model for <code>bool -&gt; bool</code>, and rather, the Bernoulli model would be induced by some source of error, such as transmission over a noisy channel, as previously described. We stick to this simple example for now, though, because it is much more managable to work with, and we can generalize the results to <code>X -&gt; Y</code> where <code>X</code> and <code>Y</code> are arbitrary types, i.e., we observe <code>bernoulli&lt;X-&gt;Y,K&gt;{f}</code> and wish to use that to compute the probability that <code>f(x) = y</code> for some <code>x in X</code> and <code>y \in Y</code>.</p>
<p>Notice that we do not change the type of the input, <code>X</code>. This is a first-order Bernoulli map. We can, of course, also provide as input to this function a Bernoulli Boolean value, e.g., <code>bernoulli&lt;bool,1&gt;{true}</code>, and we will get a an even higher-order Bernoulli Boolean value as output. In this case, we willl have a higher-order Bernoulli map of type </p><div class="fragment"><div class="line">bernoulli&lt;bool,1&gt; -&gt; bernoulli&lt;bool&gt;</div>
</div><!-- fragment --><p> where for the output we drop the order information, and track the error rates using interval arithmetic, whch we will discuss later.</p>
<p>Since functions are values, we can also ask the question, what is the probability that <code>bernoulli&lt;bool-&gt;bool,1&gt;{id} == id</code>? In this case, we are asking about the equality of the functions, which is mathematically equivalent to asking whether each input in the domain maps to the same output, i.e., </p><div class="fragment"><div class="line">Pr{bernoulli&lt;<span class="keywordtype">bool</span>-&gt;bool,1&gt;{<span class="keywordtype">id</span>}<span class="keyword">true</span>) == <span class="keywordtype">id</span>(<span class="keyword">true</span>) &amp;&amp;</div>
<div class="line">    bernoulli&lt;<span class="keywordtype">bool</span>-&gt;bool,1&gt;{<span class="keywordtype">id</span>}(<span class="keyword">false</span>) == <span class="keywordtype">id</span>(<span class="keyword">false</span>)}</div>
</div><!-- fragment --><p> Since this is a first-order model, the probability that both conditions are true is just the product of the probabilities of each condition being true, i.e., </p><div class="fragment"><div class="line">Pr{bernoulli&lt;<span class="keywordtype">bool</span>-&gt;bool&gt;,1&gt;{<span class="keywordtype">id</span>}(<span class="keyword">true</span>) == <span class="keywordtype">id</span>(<span class="keyword">true</span>)} *</div>
<div class="line">    Pr{bernoulli&lt;<span class="keywordtype">bool</span>-&gt;bool&gt;,1&gt;{<span class="keywordtype">id</span>}(<span class="keyword">false</span>) == <span class="keywordtype">id</span>(<span class="keyword">false</span>)} = p^2.</div>
</div><!-- fragment --><p>Let's fix <code>p</code> and consider the confusion matrix for the first-order model, <code>bernoulli&lt;bool-&gt;bool,1&gt;</code>. We used the standard naming convention for the outcomes of observations (<code>bernoulli&lt;bool-&gt;bool,1&gt;{f}(x)</code>) when compared against the actuality (the latent <code>f(x)</code>), where TPR is the true positive rate, FNR is the false negative rate, TNR is the true negative rate, and FPR is the false positive rate. The confusion matrix is given by Table 2.</p>
<p>Table 2: First-Order Bernoulli Model for <code>bool -&gt; bool</code> over Booleans</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone"></th><th class="markdownTableHeadNone">observe <code>true</code>   </th><th class="markdownTableHeadNone">observe <code>false</code>    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">latent <code>true</code>   </td><td class="markdownTableBodyNone">TPR <code>p</code>   </td><td class="markdownTableBodyNone">FNR <code>1-p</code>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">latent <code>false</code>   </td><td class="markdownTableBodyNone">FPR <code>1-p</code>   </td><td class="markdownTableBodyNone">TNR <code>p</code>   </td></tr>
</table>
<p>Note that in the above, we are not discussing the input &ndash; it is, after all, observable in this case. We are only discussing the output, which is latent, since we are pretending that we do not know we are dealing with, say, <code>id</code>. We are only given the observation <code>bernoulli&lt;bool-&gt;bool,1&gt;{id}</code>. As mentioned previously, there are only 4 possible functions of type <code>bool -&gt; bool</code>, so if <code>p</code> is reasonably small, we can probably estimate the true function with high confidence based on examing inputs with expected outputs.</p>
<p>We might ask the question, can the order <code>N</code> in <code>bernoulli&lt;bool-&gt;bool,N&gt;</code> be greater than 2? It is an interesting question. We only have two possible outcomes, <code>true</code> and <code>false</code>, so how could we have a higher-order model? The answer is that we are not tracking the order of the output, but rather, we are tracking the order of the Bernoulli Boolean <em>function</em> approximation. Since we know the type, <code>bool -&gt; bool</code>, we know that there are only 4 possible functions.</p>
<p>Just as before, we knew we had a Boolean value. A Boolean value can only be <code>true</code> or <code>false</code>. We can't observe the value directly, but we can observe a Bernoulli approximation of the value. For each observed value, we can have unique probability that the latent value is <code>true</code> or <code>false</code>.</p>
<p>Let's extend this to the discussion of functions of type <code>bool -&gt; bool</code>. There are only 4 possible functions of this type, <code>id</code>, <code>not</code>, <code>true</code>, and <code>false</code>.</p>
<p>Now suppose we are given a Bernoulli <code>bernoulli&lt;bool-&gt;bool&gt;{id}</code>. We do not know that the latent function is <code>id</code>, we only know that we have a function <code>bernoulli&lt;bool-&gt;bool&gt;{id}</code>, which can be either <code>id</code>, <code>not</code>, <code>true</code>, or <code>false</code>. The best guess for <code>bernoulli&lt;bool-&gt;bool&gt;{id}</code> is the function that it matches, assuming that the process that generates these approximations is unbiased.</p>
<p>Let's construct the confusion matrix for <code>bernoulli&lt;bool-&gt;bool&gt;</code>.</p>
<p>Table 3: Bernoulli Model for <code>bool -&gt; bool</code></p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">latent / observe   </th><th class="markdownTableHeadNone"><code>id</code>   </th><th class="markdownTableHeadNone"><code>not</code>   </th><th class="markdownTableHeadNone"><code>true</code>   </th><th class="markdownTableHeadNone"><code>false</code>    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>id</code>   </td><td class="markdownTableBodyNone"><code>p11</code>   </td><td class="markdownTableBodyNone"><code>p12</code>   </td><td class="markdownTableBodyNone"><code>p13</code>   </td><td class="markdownTableBodyNone"><code>p14</code>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><code>not</code>   </td><td class="markdownTableBodyNone"><code>p21</code>   </td><td class="markdownTableBodyNone"><code>p22</code>   </td><td class="markdownTableBodyNone"><code>p23</code>   </td><td class="markdownTableBodyNone"><code>p24</code>    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>true</code>   </td><td class="markdownTableBodyNone"><code>p31</code>   </td><td class="markdownTableBodyNone"><code>p32</code>   </td><td class="markdownTableBodyNone"><code>p33</code>   </td><td class="markdownTableBodyNone"><code>p34</code>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><code>false</code>   </td><td class="markdownTableBodyNone"><code>p41</code>   </td><td class="markdownTableBodyNone"><code>p42</code>   </td><td class="markdownTableBodyNone"><code>p43</code>   </td><td class="markdownTableBodyNone"><code>p44</code>   </td></tr>
</table>
<p>Each row must sum to 1, <code>\sum_j p_{i j} = 1</code>, so we only have up to a maximum of <code>4 (4-1) = 12</code> degrees of freedom. This means the highest Bernoulli Boolean order is 12 (<code>bernoulli&lt;bool-&gt;bool,12&gt;</code>), but we normally drop the order and just write <code>bernoulli&lt;bool-&gt;bool&gt;</code> and track the error rates using interval arithmetic, as mentioned a few times previously.</p>
<p>Now, when we have a Bernoulli approximation of some latent function of type <code>bool -&gt; bool</code>, we wish to store the error information in the output so that we can propagate it forward. We do this by saying that the output is a Bernoulli Boolean, because it may or may not be correct, i.e., the Bernoulli process <code>bernoulli&lt;bool-&gt;bool&gt;</code> generates a function of type <code>bool -&gt; bernoulli&lt;bool&gt;</code> rather than of type <code>bool -&gt; bool</code>. In our algorithms, we created a type system for this, and this extra information can be discarded when tracking errors is not needed.</p>
<p>So, what happens when we have a Bernoulli model <code>bernoulli&lt;bool-&gt;bool&gt;</code>, and then we lift it to </p><div class="fragment"><div class="line">bernoulli&lt;bernoulli&lt;bool&gt;-&gt;bernoulli&lt;<span class="keywordtype">bool</span>&gt;&gt;</div>
</div><!-- fragment --><p> by providing <code>bernoulli&lt;bool&gt;</code> as input? When we compare the true output with this lifted Bernoulli model, we still get a maximum order of 12, but if the order is, say, 2, then this lifted model is likely to have a higher order.</p>
<p>The order of the model is not necessarily that important, but it does complicate estimation problems, and it is also <em>desirable</em> to have a higher order models in some cases, for instance if we have an entropy coder, then we want the diagonal of the confusion matrix to be as close to 1 as possible, and we want the off-diagonal elements to be as close to 0 as possible, but when elements are not 0, we want functions that are more similiar to the latent function to have larger probabilities than functions that are less similiar to the latent function. This is just a way of minimizing a loss function in ML, where the function truly is latent and we are trying to find the best approximation to the latent function by minimizing a loss function. The higher the order, the more capacity the model has to approximate the latent function, but the more data we need to estimate the parameters of the model.</p>
<p>ML is not really the target of the Bernoulli model, but it is a useful way to think about the model. The Bernoulli model is really a way of thinking about the uncertainty in the output of a function, and how that uncertainty propagates through a computation, and typically the uncertainty is due to a trade-off between space complexity and accuracy. The more space we use to represent the function, the more closely it is expected to approximate the latent function.</p>
<h1><a class="anchor" id="autotoc_md6"></a>
Noisy Turing machines: noisy logic gates</h1>
<p>As we consider more complex compound data types, which may always be modeled as functions, we will see that there are many ways these types can participate in the Bernoulli Boolean model. When a Bernoulli value is introduced into the computational model, the entire computation outputs a final result that is a Bernoulli type, e.g., <code>bernoulli&lt;pair&lt;T1,T2&gt;&gt;</code>, <code>pair&lt;T1,bernoulli&lt;T2&gt;</code>, and so on.</p>
<p>The easiest way to think about this is to just consider a Universal Turing machine in which we build programs by composing circuits of binary logic-gates, like <code>and</code>, <code>or</code>, and <code>not</code>. In general, if we replace a single input into the circuit with a Bernoulli Boolean, the output of the circuit is a one or more Bernoulli Booleans. Moreover, and more interestingly, we can replace some of the logic gates with noisy logic-gates, or Bernoulli logic-gates, and the output of the circuit is also a Bernoulli Boolean. We can always discard information about the uncertainty in the output of the circuit, and just get Boolean, but if the uncertainty is non-negligible, then we may want to keep track of it.</p>
<p>So, let's consider the set of binary functions <code>f : (bool, bool) -&gt; bool</code>.</p>
<p>There are 2^2 = 4 possible functions <code>f : bool -&gt; bool</code> since for each possible input, <code>true</code> or <code>false</code>, we have two possible outputs, <code>true</code> or <code>false</code>.</p>
<blockquote class="doxtable">
<p>More generally, if we have <code>f : X -&gt; Y</code>, then we have <code>|Y|^|X|</code> possible functions, where <code>|.|</code> denotes the cardinality of a set. For instance, if <code>X = (bool, bool)</code> and <code>Y = bool</code>, then we have <code>2^4 = 16</code> possible functions, since <code>|X| = 4</code> and <code>|Y| = 2</code>. </p>
</blockquote>
<p>Each of these functions has a designated name, which we can use to refer to them, like <code>and</code>, <code>xor</code>, etc. However, we are just going to look at <code>and</code>.</p>
<p>Table 4: <code>and : (bool, bool) -&gt; bool</code></p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone"><code>x1</code>   </th><th class="markdownTableHeadNone"><code>x2</code>   </th><th class="markdownTableHeadNone"><code>and(x1, x2)</code>    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">true   </td><td class="markdownTableBodyNone">true   </td><td class="markdownTableBodyNone">true    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">true   </td><td class="markdownTableBodyNone">false   </td><td class="markdownTableBodyNone">false    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">false   </td><td class="markdownTableBodyNone">true   </td><td class="markdownTableBodyNone">false    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">false   </td><td class="markdownTableBodyNone">false   </td><td class="markdownTableBodyNone">false   </td></tr>
</table>
<p>Now, let's consider </p><div class="fragment"><div class="line">and : (bernoulli&lt;bool,1&gt;, bernoulli&lt;bool,1&gt;) -&gt; bernoulli&lt;bool,2&gt;`</div>
</div><!-- fragment --><p>This is more complicated than might first seem. An error occurs if <code>and</code> returns <code>true</code> when it should return <code>false</code>, or vice versa. The input variables represent <em>latent</em> values, so they do not have a definite value.</p>
<p>We will go row by row, and examine the probability that the output is correct for each <em>output</em>.</p>
<h2><a class="anchor" id="autotoc_md7"></a>
Case 1: The Correct Output Is True</h2>
<p>In order for the output to be true, both noisy inputs must be true, which is just the product of the probabilities of each condition being true since they are statistically independent outcomes.</p>
<h2><a class="anchor" id="autotoc_md8"></a>
Case 2: The Correct Output Is False Given &lt;tt&gt;x1 = true&lt;/tt&gt; and &lt;tt&gt;x2 = false&lt;/tt&gt;</h2>
<p>Consider <code>and(bernoulli&lt;bool,1&gt;{true}, bernoulli&lt;bool,1&gt;{false})</code>. For this to be true, the first must be a true positive and the second must be a false postive, which is just <code>p1 * (1-p2)</code>. Since we are interested in the probability that it correctly maps to false, that is just <code>1 - p1 * (1-p2) = 1 - p1 + p1 * p2</code>.</p>
<h2><a class="anchor" id="autotoc_md9"></a>
Case 3: The Correct Output Is False Given &lt;tt&gt;x1 = false&lt;/tt&gt; and &lt;tt&gt;x2 = true&lt;/tt&gt;</h2>
<p>Consider <code>and(bernoulli&lt;bool,1&gt;{false}, bernoulli&lt;bool,1&gt;{true})</code>. For this to be true, the first must be a false positive and the second must be a true positive, which is just <code>(1-p1) * p2</code>. Since we are interested in the probability that it maps correctly to false, that is just <code>1 - (1-p1) * p2 = 1 - p2 + p1 * p2</code>.</p>
<h2><a class="anchor" id="autotoc_md10"></a>
Case 4: The Correct Output Is False Given &lt;tt&gt;x1 = false&lt;/tt&gt; and &lt;tt&gt;x2 = false&lt;/tt&gt;</h2>
<p>Consider <code>and(bernoulli&lt;bool,1&gt;{false}, bernoulli&lt;bool,1&gt;{false})</code>. For this to be true, both must be false positives, which is just <code>(1-p1) * (1-p2)</code>. Since we are interestd in the probability that it maps correctly to false, that is just <code>1 - (1-p1) * (1-p2) = p1 + p2 - p1 * p2</code>.</p>
<h1><a class="anchor" id="autotoc_md11"></a>
Summary</h1>
<p>Table 6: <code>and</code> with Bernoulli inputs</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone"><code>x1</code>   </th><th class="markdownTableHeadNone"><code>x2</code>   </th><th class="markdownTableHeadNone"><code>and(x1,x2)</code>   </th><th class="markdownTableHeadNone"><code>Pr{correct}</code>    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">1   </td><td class="markdownTableBodyNone">1   </td><td class="markdownTableBodyNone">1   </td><td class="markdownTableBodyNone"><code>p1 * p2</code>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">1   </td><td class="markdownTableBodyNone">0   </td><td class="markdownTableBodyNone">0   </td><td class="markdownTableBodyNone"><code>1 - p1 + p1 * p2</code>    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">0   </td><td class="markdownTableBodyNone">1   </td><td class="markdownTableBodyNone">0   </td><td class="markdownTableBodyNone"><code>1 - p2 + p1 * p2</code>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">0   </td><td class="markdownTableBodyNone">0   </td><td class="markdownTableBodyNone">0   </td><td class="markdownTableBodyNone"><code>p1 + p2 - p1 * p2</code>   </td></tr>
</table>
<p>We see that <code>and : (bernoulli&lt;bool,1&gt;, bernoulli&lt;bool,1&gt;) -&gt; bernoulli&lt;bool,4&gt;</code> induces an output that is a fourth-order Bernoulli Boolean. How is this possible when there are only two possible outputs? The answer is that the output is dependent on four different combinations of inputs.</p>
<p>Since <code>x1</code> and <code>x2</code> are <em>latent</em>, we can only talk about the probability that the output is correct or not. We see that when the output is 1, the probability that the output is correct is <code>p1 * p2</code>. When the output is 0, the probability that it is correct is more complicated.</p>
<p>We could store all of this information in the type <code>bernoulli&lt;bool,4&gt;</code>, but it is probably more convenient to use interval arithmetic, where we store a range of probabilities for the probabily that the Boolean value being stored is correct. The best choice is just the minimum length interval that contains all of the relevant probabilities for the output being correct. When the output is 1, we see that the minimum spanning interval is just <code>p1 * p2</code>, and when the output is 0, the minimum spanning interval is just the minimum span of </p><div class="fragment"><div class="line">min_span{1 - p1 + p1 * p2, 1 - p2 + p1 * p2, p1 + p2 - p1 * p2}</div>
</div><!-- fragment --><p>As we compose more and more logic circuits together, we can keep track of the minimum spanning intervals on outputs using interval arithmetic.</p>
<p>Let's come back to the idea of Bernoulli types over compound types. In particular, let's consider applynig the Bernoulli approximation to binary functions of the type <code>(bool, bool) -&gt; bool</code>.</p>
<p>Now, we can apply the Bernoulli approximation </p><div class="fragment"><div class="line">bernoulli&lt;(bool, bool) -&gt; <span class="keywordtype">bool</span>&gt;</div>
</div><!-- fragment --><p> which will generate functions of the type </p><div class="fragment"><div class="line">(bool, bool) -&gt; bernoulli&lt;bool&gt;</div>
</div><!-- fragment --><p>This may be thought of as a <em>noisy</em> binary logic-gate. For the case of the <code>and</code> gate, what we observe in our model is <code>bernoulli&lt;(bool, bool) -&gt; bool&gt;{and}</code>, and it can generate up to 16 different Bernoulli Boolean functions. That means that the maximum order is <code>16 (16 - 1) = 240</code>, which isn't really important, but it's interesting to note.</p>
<p>Of course, if we have this noisy <code>and</code> function and then put in noisy inputs, then we get a function of type </p><div class="fragment"><div class="line">(bernoulli&lt;bool&gt;, bernoulli&lt;bool&gt;) -&gt; bernoulli&lt;bool&gt;</div>
</div><!-- fragment --> </div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1 </li>
  </ul>
</div>
</body>
</html>
